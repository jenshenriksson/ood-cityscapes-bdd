{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2795027",
   "metadata": {},
   "source": [
    "## Find differences in class names of the two datasets\n",
    "\n",
    "We do this by adding two lists, one for each dataset with the class labels given from their corresponding descriptions found here: \n",
    "\n",
    "- [CityScapes class description](https://www.cityscapes-dataset.com/dataset-overview/)\n",
    "- [BDD100K Semantic Segmentation class description](https://doc.bdd100k.com/format.html#semantic-segmentation) \n",
    "\n",
    "This notebook is just for studying the dataset and does not do anything practical. The summary variation of the classes is done in GIT/utils/dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5a4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "CITYSCAPES = [\n",
    "    'unlabeled', 'ego vehicle' ,'rectification border', 'out of roi', 'static', 'dynamic', 'ground',  # Category \"void\": 0\n",
    "    'road', 'sidewalk', 'parking', 'rail track',  # Category \"Flat\": 1 \n",
    "    'building', 'wall', 'fence', 'guard rail', 'bridge', 'tunnel',  # Category \"construction\": 2\n",
    "    'pole', 'polegroup', 'traffic light', 'traffic sign',  # Category \"object\": 3\n",
    "    'vegetation', 'terrain',  # Category \"nature\": 4\n",
    "    'sky',  # Category \"sky\": 5\n",
    "    'person', 'rider',  # Category \"human\": 6\n",
    "    'car', 'truck', 'bus', 'caravan', 'trailer', 'train', 'motorcycle', 'bicycle', 'license plate',  # Category \"vehicle\": 7\n",
    "]\n",
    "\n",
    "BDD100K = [\n",
    "    'road', 'sidewalk', 'building', 'wall', 'fence',\n",
    "    'pole', 'traffic light', 'traffic sign',\n",
    "    'vegetation', 'terrain', 'sky', \n",
    "    'person', 'rider',  \n",
    "    'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle',  \n",
    "    'unknown',  # Not used for evaluation, but pixel values 255 (white)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e757058",
   "metadata": {},
   "source": [
    "Print out all classes found in both datasets. Also, which ones are in one or the other? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce28520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint classes:\n",
      "['road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light', 'traffic sign', 'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle']\n",
      "\n",
      "Only in BDD100K:\n",
      "['unknown']\n",
      "\n",
      "Only in CityScapes:\n",
      "['unlabeled', 'ego vehicle', 'rectification border', 'out of roi', 'static', 'dynamic', 'ground', 'parking', 'rail track', 'guard rail', 'bridge', 'tunnel', 'polegroup', 'caravan', 'trailer', 'license plate']\n"
     ]
    }
   ],
   "source": [
    "print(\"Joint classes:\")\n",
    "joint_classes = [j for j in CITYSCAPES if j in BDD100K]\n",
    "print(joint_classes)\n",
    "\n",
    "print(\"\\nOnly in BDD100K:\")\n",
    "only_in_BDD100K = [j for j in BDD100K if j not in CITYSCAPES]\n",
    "print(only_in_BDD100K)\n",
    "\n",
    "print(\"\\nOnly in CityScapes:\")\n",
    "only_in_cityscapes = [j for j in CITYSCAPES if j not in BDD100K]\n",
    "print(only_in_cityscapes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c8e751",
   "metadata": {},
   "source": [
    "## Summary: Class-labels \n",
    "#### Issues\n",
    "- BDD100K has grouped buildings into a broader class, whereas CityScapes have detailed it into more specific classes e.g. guard rail, bridge, tunnel etc. \n",
    "- CityScapes have, in general, more descriptive classes. Some classes can be merged, e.g. \"pole\" with \"pole group\"\n",
    "\n",
    "#### What do we do?\n",
    "From Cityscape, convert the following:  \n",
    "- Move guard rail to fence class. \n",
    "- Move bridge and tunnel to buildings class. \n",
    "- Move polegroup to pole class. \n",
    "- Move caravan, trailer and license plate to car. \n",
    "\n",
    "- Move parking to road, as we consider it an area where the vehicle may drive/park. \n",
    "- Move ground to terrain, as it is part of the area where a vehicle is not supposed to drive.  \n",
    "- Move rail track to terrain, as it is part of the area where a vehicle is not supposed to drive. \n",
    "\n",
    "#### Ignoring classes out of scope/Unknown\n",
    "Ignore the following CityScapes classes: \n",
    "- Unlabled\n",
    "- Ego Vehicle\n",
    "- Rectification border\n",
    "- Out of ROI\n",
    "- Static\n",
    "- Dynamic\n",
    "\n",
    "Ignore the following BDD100K classes:\n",
    "- Unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f042c51",
   "metadata": {},
   "source": [
    "## Find the pixel distribution of classes in the two datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4d8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import utils.utils as CU\n",
    "import utils.dataloaders as CD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a093b8",
   "metadata": {},
   "source": [
    "\n",
    "### BDD100K \n",
    "Replace location of BDD100K images. Requires you to have converted the dataset to CityScapes format beforehand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c45b310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ml-data-storage/jens/BDD100K/labels\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '/mnt/ml-data-storage/jens/BDD100K/images'\n",
    "LABEL_DIR = DATA_DIR.replace('images', 'labels')\n",
    "print(LABEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a490ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load repo with data\n",
    "training_images = sorted(CU.list_dir_recursive(os.path.join(DATA_DIR, 'train')))\n",
    "training_labels = sorted(CU.list_dir_recursive(os.path.join(LABEL_DIR, 'train'), '-mask.png'))\n",
    "\n",
    "validation_images = sorted(CU.list_dir_recursive(os.path.join(DATA_DIR, 'val')))\n",
    "validation_labels = sorted(CU.list_dir_recursive(os.path.join(LABEL_DIR, 'val'), '-mask.png'))\n",
    "\n",
    "test_images = sorted(CU.list_dir_recursive(os.path.join(DATA_DIR, 'test')))\n",
    "test_labels = sorted(CU.list_dir_recursive(os.path.join(LABEL_DIR, 'test'), '-mask.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa794b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "bdd100k = CD.BDD100K(training_images, training_labels, classes=CD.BDD100K.CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd9bb1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfb658d722348bd9db985c37a955d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dimension of the BDD100K images are 720x1280 (Height * Width)\n",
    "DIM = 720*1280\n",
    "\n",
    "bdd100k_classes = len(CD.BDD100K.CLASSES)\n",
    "bdd100k_distribution = np.zeros((bdd100k_classes,1))\n",
    "\n",
    "for _, lb in tqdm(bdd100k):\n",
    "    for c in range(bdd100k_classes): \n",
    "        bdd100k_distribution[c] += np.sum(lb[:,:,c])/DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1df33339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road: 20.653%\n",
      "sidewalk: 2.108%\n",
      "building: 15.427%\n",
      "wall: 0.512%\n",
      "fence: 1.111%\n",
      "pole: 1.004%\n",
      "traffic light: 0.268%\n",
      "traffic sign: 0.412%\n",
      "vegetation: 11.717%\n",
      "terrain: 0.784%\n",
      "sky: 11.645%\n",
      "person: 0.327%\n",
      "rider: 0.024%\n",
      "car: 8.712%\n",
      "truck: 1.107%\n",
      "bus: 0.674%\n",
      "train: 0.013%\n",
      "motorcycle: 0.018%\n",
      "bicycle: 0.073%\n",
      "unknown: 0.0%\n",
      "Unlabeled: 23.413%\n"
     ]
    }
   ],
   "source": [
    "for name, part in zip(BDD100K, bdd100k_distribution): \n",
    "    val = np.round(part[0]/len(bdd100k)*100, 3)\n",
    "    print('{}: {}%'.format(name, val)) \n",
    "\n",
    "val = round(100-(np.sum(bdd100k_distribution/len(bdd100k)*100)), 3) \n",
    "print('Unlabeled: {}%'.format(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85cff9f",
   "metadata": {},
   "source": [
    "\n",
    "### CityScapes\n",
    "Do the same thing for CityScapes.\n",
    "\n",
    "Change the path to your DATA_DIR. Requires you to have re-arranged the dataset as described in Data-prep notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "043347ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/ml-data-storage/jens/CityScapes/images'\n",
    "LABEL_DIR = DATA_DIR.replace('images', 'labels')\n",
    "\n",
    "training_images = sorted(CU.list_dir_recursive(os.path.join(DATA_DIR, 'train')))\n",
    "training_labels = sorted(CU.list_dir_recursive(os.path.join(LABEL_DIR, 'train'), 'labelIds.png'))\n",
    "\n",
    "cityscapes = CD.CityScapes(training_images, training_labels, classes=CD.CityScapes.CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a734ccc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09ba1279f484f6293ff95abe85b9487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Image dimensions for CityScapes are 2048 x 1024 pixels (Width * Height)\n",
    "DIM = 1024*2048\n",
    "\n",
    "cityscapes_classes = len(CD.CityScapes.CLASSES)\n",
    "cityscapes_distribution = np.zeros((cityscapes_classes,1))\n",
    "\n",
    "for _, lb in tqdm(cityscapes):\n",
    "    for c in range(cityscapes_classes): \n",
    "        cityscapes_distribution[c] += np.sum(lb[:,:,c])/DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f26e535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unlabeled: 0.008%\n",
      "ego vehicle: 4.445%\n",
      "rectification border: 1.043%\n",
      "out of roi: 1.508%\n",
      "static: 1.323%\n",
      "dynamic: 0.25%\n",
      "ground: 1.299%\n",
      "road: 32.538%\n",
      "sidewalk: 5.453%\n",
      "parking: 0.544%\n",
      "rail track: 0.18%\n",
      "building: 21.2%\n",
      "wall: 0.674%\n",
      "fence: 0.809%\n",
      "guard rail: 0.01%\n",
      "bridge: 0.119%\n",
      "tunnel: 0.05%\n",
      "pole: 1.047%\n",
      "polegroup: 0.007%\n",
      "traffic light: 0.174%\n",
      "traffic sign: 0.472%\n",
      "vegetation: 14.198%\n",
      "terrain: 1.017%\n",
      "sky: 3.382%\n",
      "person: 1.007%\n",
      "rider: 0.105%\n",
      "car: 6.131%\n",
      "truck: 0.201%\n",
      "bus: 0.148%\n",
      "caravan: 0.033%\n",
      "trailer: 0.016%\n",
      "train: 0.22%\n",
      "motorcycle: 0.094%\n",
      "bicycle: 0.294%\n",
      "license plate: 0.0%\n",
      "Unlabeled: 0.0%\n"
     ]
    }
   ],
   "source": [
    "for name, part in zip(CITYSCAPES, cityscapes_distribution): \n",
    "    val = np.round(part[0]/len(cityscapes)*100, 3)\n",
    "    print('{}: {}%'.format(name, val)) \n",
    "\n",
    "val = round(100-(np.sum(cityscapes_distribution/len(cityscapes)*100)), 3) \n",
    "print('Unlabeled: {}%'.format(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64cc3ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/ml-data-storage/jens/CityScapes/images'\n",
    "LABEL_DIR = DATA_DIR.replace('images', 'labels')\n",
    "\n",
    "training_images = sorted(CU.list_dir_recursive(os.path.join(DATA_DIR, 'train')))\n",
    "training_labels = sorted(CU.list_dir_recursive(os.path.join(LABEL_DIR, 'train'), 'labelIds.png'))\n",
    "\n",
    "cityscapes = CD.CityScapes_bdd100k_class_merge(training_images, training_labels, classes=CD.CityScapes_bdd100k_class_merge.CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ba32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22baeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be8bb24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
